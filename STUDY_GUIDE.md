# AI Assistant ì†ŒìŠ¤ì½”ë“œ í•™ìŠµ ê°€ì´ë“œ

> **ëª©í‘œ**: FastAPI + OpenSearch + OpenAIë¥¼ í™œìš©í•œ RAG ê¸°ë°˜ AI Assistant ì‹œìŠ¤í…œì„ ë‹¨ê³„ë³„ë¡œ ì´í•´í•˜ê¸°

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#1-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‚¬ì „ ì§€ì‹](#2-ì‚¬ì „-ì§€ì‹)
3. [í•™ìŠµ ë¡œë“œë§µ](#3-í•™ìŠµ-ë¡œë“œë§µ)
4. [ë‹¨ê³„ë³„ í•™ìŠµ ê°€ì´ë“œ](#4-ë‹¨ê³„ë³„-í•™ìŠµ-ê°€ì´ë“œ)
5. [ì‹¤ìŠµ ì˜ˆì œ](#5-ì‹¤ìŠµ-ì˜ˆì œ)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#6-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚  (Browser)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP/REST
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Application             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      API Layer (REST)          â”‚    â”‚
â”‚  â”‚  - chat.py                     â”‚    â”‚
â”‚  â”‚  - documents.py                â”‚    â”‚
â”‚  â”‚  - health.py                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Core Business Logic       â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚   RAG Engine             â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  - ë¬¸ì„œ ê²€ìƒ‰             â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  - í•˜ì´ë¸Œë¦¬ë“œ ì„œì¹˜       â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  â”‚   LLM Client (OpenAI)    â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  - GPT-4o í˜¸ì¶œ           â”‚  â”‚    â”‚
â”‚  â”‚  â”‚  - ë‹µë³€ ìƒì„±             â”‚  â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚            â”‚
         â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenSearch â”‚  â”‚   OpenAI     â”‚
â”‚  (Vector   â”‚  â”‚   API        â”‚
â”‚   Store)   â”‚  â”‚ (GPT-4o)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 í•µì‹¬ ê¸°ëŠ¥

1. **ë¬¸ì„œ ê´€ë¦¬**: ë¬¸ì„œ ì¶”ê°€/ê²€ìƒ‰/ì‚­ì œ (ì¡°ì§/ì‚¬ìš©ìë³„ ê²©ë¦¬)
2. **ë²¡í„° ê²€ìƒ‰**: OpenSearch k-NNì„ í™œìš©í•œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
3. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: í‚¤ì›Œë“œ ë§¤ì¹­ + ë²¡í„° ìœ ì‚¬ë„ ê²°í•©
4. **RAG ì§ˆì˜ì‘ë‹µ**: ê²€ìƒ‰ëœ ë¬¸ì„œ ê¸°ë°˜ AI ë‹µë³€ ìƒì„±
5. **ëŒ€í™” ì´ë ¥ ê´€ë¦¬**: Redis ê¸°ë°˜ ì„¸ì…˜ ê´€ë¦¬

### 1.3 ê¸°ìˆ  ìŠ¤íƒ

| ì˜ì—­ | ê¸°ìˆ  | ìš©ë„ |
|------|------|------|
| **ì›¹ í”„ë ˆì„ì›Œí¬** | FastAPI 0.115.5 | REST API ì„œë²„ |
| **LLM** | OpenAI GPT-4o | ìì—°ì–´ ìƒì„± |
| **ë²¡í„° DB** | OpenSearch 3.3.2 | ë¬¸ì„œ ì €ì¥ + ë²¡í„° ê²€ìƒ‰ |
| **ì„ë² ë”©** | OpenAI text-embedding-3-large | í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜ (3072ì°¨ì›) |
| **ìºì‹œ/ì„¸ì…˜** | Redis | ëŒ€í™” ì´ë ¥ ì €ì¥ |
| **ë¡œê¹…** | Structlog | êµ¬ì¡°í™”ëœ JSON ë¡œê¹… |

---

## 2. ì‚¬ì „ ì§€ì‹

### 2.1 í•„ìˆ˜ ê°œë…

í•™ìŠµ ì „ì— ë‹¤ìŒ ê°œë…ì„ ì´í•´í•˜ê³  ìˆì–´ì•¼ í•©ë‹ˆë‹¤:

#### Python ê¸°ì´ˆ
- [ ] íƒ€ì… íŒíŒ… (Type Hints)
- [ ] ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° (async/await)
- [ ] ë°ì½”ë ˆì´í„° (Decorator)
- [ ] Pydantic ëª¨ë¸

#### FastAPI
- [ ] ë¼ìš°í„°ì™€ ì—”ë“œí¬ì¸íŠ¸
- [ ] Request/Response ëª¨ë¸
- [ ] ì˜ì¡´ì„± ì£¼ì… (Dependency Injection)
- [ ] CORS ì„¤ì •

#### RAG (Retrieval-Augmented Generation)
- [ ] ì„ë² ë”© (Embedding)ì´ë€?
- [ ] ë²¡í„° ê²€ìƒ‰ ì›ë¦¬
- [ ] k-NN (k-Nearest Neighbors)
- [ ] ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (Cosine Similarity)

#### OpenSearch
- [ ] ì¸ë±ìŠ¤ì™€ ë¬¸ì„œ ê°œë…
- [ ] k-NN ë²¡í„° ê²€ìƒ‰
- [ ] HNSW ì•Œê³ ë¦¬ì¦˜
- [ ] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ë²¡í„°)

### 2.2 ê¶Œì¥ í•™ìŠµ ìë£Œ

1. **FastAPI ê³µì‹ ë¬¸ì„œ**: https://fastapi.tiangolo.com/
2. **OpenSearch k-NN ê°€ì´ë“œ**: https://opensearch.org/docs/latest/search-plugins/knn/
3. **OpenAI Embeddings**: https://platform.openai.com/docs/guides/embeddings
4. **RAG ê°œë… ì´í•´**: https://www.pinecone.io/learn/retrieval-augmented-generation/

---

## 3. í•™ìŠµ ë¡œë“œë§µ

### 3.1 ì „ì²´ í•™ìŠµ ìˆœì„œ (ì´ 8ë‹¨ê³„)

```
ğŸ“š Level 1: ê¸°ì´ˆ (1-2ì¼)
â””â”€ Step 1: í”„ë¡œì íŠ¸ êµ¬ì¡° íŒŒì•…
â””â”€ Step 2: í™˜ê²½ ì„¤ì • ì´í•´

ğŸ”§ Level 2: ìœ í‹¸ë¦¬í‹° (1ì¼)
â””â”€ Step 3: ë¡œê¹…ê³¼ Redis í´ë¼ì´ì–¸íŠ¸

ğŸ“¦ Level 3: ë°ì´í„° ëª¨ë¸ (1ì¼)
â””â”€ Step 4: Pydantic ëª¨ë¸ êµ¬ì¡°

ğŸ§  Level 4: í•µì‹¬ ë¡œì§ (3-4ì¼) â˜… ê°€ì¥ ì¤‘ìš” â˜…
â””â”€ Step 5: OpenAI í´ë¼ì´ì–¸íŠ¸
â””â”€ Step 6: OpenSearch ë²¡í„° ìŠ¤í† ì–´
â””â”€ Step 7: RAG ì—”ì§„

ğŸŒ Level 5: API ë ˆì´ì–´ (2ì¼)
â””â”€ Step 8: REST API ì—”ë“œí¬ì¸íŠ¸

ğŸš€ Level 6: í†µí•© ë° ì‹¤ìŠµ (1-2ì¼)
â””â”€ Step 9: ì „ì²´ í”Œë¡œìš° ì´í•´
â””â”€ Step 10: ì‹¤ìŠµ ì˜ˆì œ
```

### 3.2 ì˜ˆìƒ ì†Œìš” ì‹œê°„

- **ë¹ ë¥¸ í•™ìŠµ**: 5-7ì¼ (í•˜ë£¨ 4ì‹œê°„)
- **ê¹Šì´ ìˆëŠ” í•™ìŠµ**: 10-14ì¼ (í•˜ë£¨ 2-3ì‹œê°„)
- **ì™„ë²½í•œ ì´í•´**: 3ì£¼ ì´ìƒ (ì‹¤ìŠµ í¬í•¨)

---

## 4. ë‹¨ê³„ë³„ í•™ìŠµ ê°€ì´ë“œ

---

## ğŸ“š Step 1: í”„ë¡œì íŠ¸ êµ¬ì¡° íŒŒì•… (30ë¶„)

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
ai-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # â­ FastAPI ì•± ì§„ì…ì 
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py         # â­ í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì •
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.py           # êµ¬ì¡°í™”ëœ ë¡œê¹…
â”‚   â”‚   â””â”€â”€ redis_client.py     # Redis ì—°ê²°
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ chat.py             # Pydantic ë°ì´í„° ëª¨ë¸
â”‚   â”œâ”€â”€ core/                   # â­ í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â””â”€â”€ openai_client.py    # OpenAI API í˜¸ì¶œ
â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”œâ”€â”€ opensearch_store.py # â­ OpenSearch ë²¡í„° DB
â”‚   â”‚   â”‚   â””â”€â”€ rag_engine.py       # â­ RAG ì—”ì§„ (í•µì‹¬!)
â”‚   â”‚   â”œâ”€â”€ memory/             # ëŒ€í™” ì´ë ¥ ê´€ë¦¬
â”‚   â”‚   â””â”€â”€ agent/              # AI ì—ì´ì „íŠ¸ (í–¥í›„ í™•ì¥)
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ rest/
â”‚           â”œâ”€â”€ chat.py         # â­ ì±„íŒ… API
â”‚           â”œâ”€â”€ documents.py    # â­ ë¬¸ì„œ ê´€ë¦¬ API
â”‚           â””â”€â”€ health.py       # í—¬ìŠ¤ ì²´í¬
â”œâ”€â”€ .env                        # í™˜ê²½ ë³€ìˆ˜ (ë¹„ë°€!)
â”œâ”€â”€ requirements.txt
â””â”€â”€ test_opensearch_connection.py  # OpenSearch ì—°ê²° í…ŒìŠ¤íŠ¸
```

### ì¤‘ìš”ë„ë³„ íŒŒì¼ ìš°ì„ ìˆœìœ„

#### â­â­â­ í•„ìˆ˜ (ê¼­ ì´í•´í•´ì•¼ í•¨)
1. `src/main.py` - ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
2. `src/config/settings.py` - ëª¨ë“  ì„¤ì •ì˜ ì¤‘ì•™ ê´€ë¦¬
3. `src/core/rag/opensearch_store.py` - ë²¡í„° ê²€ìƒ‰ì˜ í•µì‹¬
4. `src/core/rag/rag_engine.py` - RAG ë¡œì§ì˜ ì¤‘ì‹¬
5. `src/api/rest/chat.py` - ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
6. `src/api/rest/documents.py` - ë¬¸ì„œ ê´€ë¦¬ API

#### â­â­ ì¤‘ìš” (ì´í•´í•˜ë©´ ì¢‹ìŒ)
7. `src/core/llm/openai_client.py` - LLM í†µì‹ 
8. `src/utils/logger.py` - ë¡œê¹… ì‹œìŠ¤í…œ
9. `src/models/chat.py` - ë°ì´í„° ëª¨ë¸

#### â­ ì„ íƒ (í•„ìš”ì‹œ ì°¸ê³ )
10. `src/utils/redis_client.py` - ì„¸ì…˜ ê´€ë¦¬

---

## ğŸ“š Step 2: í™˜ê²½ ì„¤ì • ì´í•´ (1ì‹œê°„)

### íŒŒì¼: `src/config/settings.py`

**í•™ìŠµ ëª©í‘œ**:
- Pydantic Settings ì‚¬ìš©ë²• ì´í•´
- í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ ë°©ë²• í•™ìŠµ

**í•µì‹¬ ì½”ë“œ ì½ê¸°**:

```python
# src/config/settings.py

from pydantic_settings import BaseSettings
from pydantic import Field

class Settings(BaseSettings):
    """
    í™˜ê²½ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” ì„¤ì • í´ë˜ìŠ¤
    .env íŒŒì¼ì˜ ê°’ì„ ìë™ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤
    """

    # OpenAI ì„¤ì •
    openai_api_key: str = Field(...)  # í•„ìˆ˜ ê°’
    openai_model: str = Field(default="gpt-4o")  # ê¸°ë³¸ê°’ ì§€ì •

    # OpenSearch ì„¤ì •
    opensearch_host: str = Field(default="localhost")
    opensearch_port: int = Field(default=9200)

    class Config:
        env_file = ".env"  # .env íŒŒì¼ì—ì„œ ìë™ ë¡œë“œ
        case_sensitive = False  # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì•ˆí•¨
```

**í•™ìŠµ í¬ì¸íŠ¸**:
1. `BaseSettings` ìƒì†ìœ¼ë¡œ ìë™ í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
2. `Field(...)`ëŠ” í•„ìˆ˜, `Field(default=ê°’)`ì€ ì„ íƒ
3. íƒ€ì… íŒíŒ…ìœ¼ë¡œ ìë™ íƒ€ì… ë³€í™˜ (ì˜ˆ: "9200" â†’ 9200)

**ì‹¤ìŠµ**:
```bash
# .env íŒŒì¼ í™•ì¸
cat .env | grep OPENSEARCH

# Python ì½˜ì†”ì—ì„œ í…ŒìŠ¤íŠ¸
python3 -c "from src.config.settings import settings; print(settings.opensearch_host)"
```

---

## ğŸ”§ Step 3: ë¡œê¹…ê³¼ ìœ í‹¸ë¦¬í‹° (1ì‹œê°„)

### íŒŒì¼: `src/utils/logger.py`

**í•™ìŠµ ëª©í‘œ**:
- Structlogë¥¼ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ë¡œê¹…
- JSON í˜•ì‹ ë¡œê·¸ì˜ ì¥ì  ì´í•´

**í•µì‹¬ ê°œë…**:

```python
# src/utils/logger.py

import structlog

# êµ¬ì¡°í™”ëœ ë¡œê±° ì„¤ì •
structlog.configure(
    processors=[
        structlog.processors.add_log_level,  # ë¡œê·¸ ë ˆë²¨ ì¶”ê°€
        structlog.processors.TimeStamper(fmt="iso"),  # ISO ì‹œê°„ ì¶”ê°€
        structlog.processors.JSONRenderer()  # JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
    ]
)

logger = structlog.get_logger()

# ì‚¬ìš© ì˜ˆ
logger.info("ì‚¬ìš©ì ë¡œê·¸ì¸", user_id="user123", organization_id="org456")
# ì¶œë ¥: {"event":"ì‚¬ìš©ì ë¡œê·¸ì¸","user_id":"user123","organization_id":"org456","level":"info","timestamp":"2025-12-01T15:00:00"}
```

**ì™œ JSON ë¡œê·¸ì¸ê°€?**
- âœ… ê²€ìƒ‰ ê°€ëŠ¥ (ELK/Splunk ë“±)
- âœ… êµ¬ì¡°í™”ëœ ë°ì´í„°
- âœ… ìë™ í•„í„°ë§/ì§‘ê³„ ê°€ëŠ¥

---

## ğŸ“¦ Step 4: ë°ì´í„° ëª¨ë¸ (1-2ì‹œê°„)

### íŒŒì¼: `src/models/chat.py`

**í•™ìŠµ ëª©í‘œ**:
- Pydantic ëª¨ë¸ë¡œ ìš”ì²­/ì‘ë‹µ ê²€ì¦
- íƒ€ì… ì•ˆì „ì„± í™•ë³´

**í•µì‹¬ ì½”ë“œ**:

```python
# src/models/chat.py

from pydantic import BaseModel, Field
from typing import Optional, List

class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­ ëª¨ë¸"""
    message: str = Field(
        ...,
        min_length=1,
        max_length=2000,
        description="ì‚¬ìš©ì ë©”ì‹œì§€"
    )
    organization_id: str = Field(..., description="ì¡°ì§ ID")
    user_id: str = Field(..., description="ì‚¬ìš©ì ID")
    session_id: Optional[str] = Field(None, description="ì„¸ì…˜ ID (ì„ íƒ)")

class ChatResponse(BaseModel):
    """ì±„íŒ… ì‘ë‹µ ëª¨ë¸"""
    session_id: str
    message: str
    sources: List[dict]
    timestamp: str
```

**Pydanticì˜ ì¥ì **:
1. **ìë™ ê²€ì¦**: `min_length`, `max_length` ìë™ ì²´í¬
2. **íƒ€ì… ë³€í™˜**: ë¬¸ìì—´ â†’ ì •ìˆ˜ ìë™ ë³€í™˜
3. **ë¬¸ì„œí™”**: FastAPI Swaggerì— ìë™ í‘œì‹œ
4. **IDE ì§€ì›**: ìë™ì™„ì„±ê³¼ íƒ€ì… ì²´í¬

**ì‹¤ìŠµ**:
```python
# Python ì½˜ì†”ì—ì„œ
from src.models.chat import ChatRequest

# ì •ìƒ ì¼€ì´ìŠ¤
req = ChatRequest(message="ì•ˆë…•", organization_id="org1", user_id="user1")
print(req.message)

# ì—ëŸ¬ ì¼€ì´ìŠ¤ (ìë™ ê²€ì¦)
try:
    req = ChatRequest(message="", organization_id="org1")  # ë¹ˆ ë©”ì‹œì§€, user_id ëˆ„ë½
except Exception as e:
    print(e)
```

---

## ğŸ§  Step 5: OpenAI í´ë¼ì´ì–¸íŠ¸ (2ì‹œê°„)

### íŒŒì¼: `src/core/llm/openai_client.py`

**í•™ìŠµ ëª©í‘œ**:
- OpenAI API í˜¸ì¶œ ë°©ë²•
- ì„ë² ë”©ê³¼ ì±„íŒ… API ì°¨ì´ ì´í•´

**í•µì‹¬ ê°œë…**:

### 5.1 ì„ë² ë”© ìƒì„±

```python
# src/core/llm/openai_client.py

from openai import OpenAI

client = OpenAI(api_key=settings.openai_api_key)

def get_embedding(text: str) -> List[float]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜

    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸ (ì˜ˆ: "OpenSearchëŠ” ê²€ìƒ‰ ì—”ì§„ì…ë‹ˆë‹¤")

    Returns:
        3072ì°¨ì› ë²¡í„° (ì˜ˆ: [0.12, -0.34, 0.56, ...])
    """
    response = client.embeddings.create(
        model="text-embedding-3-large",  # 3072ì°¨ì›
        input=text
    )
    return response.data[0].embedding
```

**ì„ë² ë”©ì´ë€?**
- í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë°°ì—´(ë²¡í„°)ë¡œ ë³€í™˜
- ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ â†’ ë¹„ìŠ·í•œ ë²¡í„°
- ì˜ˆ:
  ```
  "ê°•ì•„ì§€" â†’ [0.8, 0.2, -0.1, ...]
  "ê°œ" â†’ [0.79, 0.21, -0.09, ...]  # ë¹„ìŠ·í•¨!
  "ìë™ì°¨" â†’ [-0.3, 0.9, 0.5, ...]  # ë‹¤ë¦„
  ```

### 5.2 ì±„íŒ… ì™„ì„±

```python
def chat_completion(messages: List[dict]) -> str:
    """
    ëŒ€í™” ë©”ì‹œì§€ë¡œ AI ë‹µë³€ ìƒì„±

    Args:
        messages: [
            {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ AIì•¼"},
            {"role": "user", "content": "ì•ˆë…•?"}
        ]

    Returns:
        AI ë‹µë³€ (ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")
    """
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.7,
        max_tokens=2000
    )
    return response.choices[0].message.content
```

**ì‹¤ìŠµ**:
```python
# ì„ë² ë”© í…ŒìŠ¤íŠ¸
from src.core.llm.openai_client import OpenAIClient
from src.config.settings import settings

llm = OpenAIClient(api_key=settings.openai_api_key)

# 1. ì„ë² ë”© ìƒì„±
vec1 = llm.get_embedding("ê°•ì•„ì§€")
vec2 = llm.get_embedding("ê°œ")
vec3 = llm.get_embedding("ìë™ì°¨")

print(f"ë²¡í„° ì°¨ì›: {len(vec1)}")  # 3072
print(f"vec1 ì²˜ìŒ 5ê°œ: {vec1[:5]}")

# 2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
import numpy as np
similarity_12 = np.dot(vec1, vec2)  # ê°•ì•„ì§€ vs ê°œ â†’ ë†’ìŒ
similarity_13 = np.dot(vec1, vec3)  # ê°•ì•„ì§€ vs ìë™ì°¨ â†’ ë‚®ìŒ

print(f"ê°•ì•„ì§€-ê°œ ìœ ì‚¬ë„: {similarity_12}")
print(f"ê°•ì•„ì§€-ìë™ì°¨ ìœ ì‚¬ë„: {similarity_13}")
```

---

## ğŸ§  Step 6: OpenSearch ë²¡í„° ìŠ¤í† ì–´ (4-5ì‹œê°„) â­ ê°€ì¥ ì¤‘ìš”!

### íŒŒì¼: `src/core/rag/opensearch_store.py`

**í•™ìŠµ ëª©í‘œ**:
- OpenSearch k-NN ë²¡í„° ê²€ìƒ‰ ì›ë¦¬
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„ ë°©ë²•
- HNSW ì•Œê³ ë¦¬ì¦˜ ì´í•´

### 6.1 ì¸ë±ìŠ¤ ë§¤í•‘ (ìŠ¤í‚¤ë§ˆ)

```python
# src/core/rag/opensearch_store.py

def _create_index_mapping(self) -> dict:
    """
    OpenSearch ì¸ë±ìŠ¤ êµ¬ì¡° ì •ì˜

    ì¸ë±ìŠ¤ = ê´€ê³„í˜• DBì˜ í…Œì´ë¸”ê³¼ ìœ ì‚¬
    ë§¤í•‘ = í…Œì´ë¸”ì˜ ìŠ¤í‚¤ë§ˆ ì •ì˜
    """
    return {
        "settings": {
            "index": {
                "knn": True,  # k-NN ê²€ìƒ‰ í™œì„±í™”
                "number_of_shards": 1,
                "number_of_replicas": 0
            }
        },
        "mappings": {
            "properties": {
                # í…ìŠ¤íŠ¸ í•„ë“œ (í‚¤ì›Œë“œ ê²€ìƒ‰ìš©)
                "text": {
                    "type": "text",
                    "analyzer": "standard"  # í˜•íƒœì†Œ ë¶„ì„
                },

                # ë²¡í„° í•„ë“œ (ì˜ë¯¸ ê²€ìƒ‰ìš©) â­ í•µì‹¬!
                "embedding": {
                    "type": "knn_vector",
                    "dimension": 3072,  # OpenAI embedding í¬ê¸°
                    "method": {
                        "name": "hnsw",  # ì•Œê³ ë¦¬ì¦˜
                        "space_type": "cosinesimil",  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                        "engine": "lucene",  # OpenSearch 3.0+
                        "parameters": {
                            "ef_construction": 128,  # ì¸ë±ì‹± í’ˆì§ˆ
                            "m": 24  # ê·¸ë˜í”„ ì—°ê²° ìˆ˜
                        }
                    }
                },

                # í•„í„°ë§ í•„ë“œë“¤
                "organization_id": {"type": "keyword"},
                "user_id": {"type": "keyword"},
                "tags": {"type": "keyword"},  # ë°°ì—´ ì €ì¥ ê°€ëŠ¥
                "created_at": {"type": "date"}
            }
        }
    }
```

**í•µì‹¬ ê°œë…**:

1. **knn_vector íƒ€ì…**: ë²¡í„° ì €ì¥ + ê²€ìƒ‰ìš© íŠ¹ìˆ˜ íƒ€ì…
2. **HNSW ì•Œê³ ë¦¬ì¦˜**: Hierarchical Navigable Small World
   - ê·¸ë˜í”„ ê¸°ë°˜ ê·¼ì‚¬ ìµœê·¼ì ‘ ì´ì›ƒ ê²€ìƒ‰
   - ì •í™•ë„ vs ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„
   - `ef_construction` ë†’ì„ìˆ˜ë¡ â†’ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼
   - `m` ë†’ì„ìˆ˜ë¡ â†’ ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©, ì •í™•ë„ í–¥ìƒ

3. **space_type="cosinesimil"**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©
   ```
   similarity = cos(Î¸) = (AÂ·B) / (|A||B|)

   ë²”ìœ„: -1 ~ 1
   - 1: ì™„ì „ ê°™ì€ ë°©í–¥ (ìœ ì‚¬í•¨)
   - 0: ì§ê° (ë¬´ê´€)
   - -1: ë°˜ëŒ€ ë°©í–¥ (ë°˜ëŒ€ ì˜ë¯¸)
   ```

### 6.2 ë¬¸ì„œ ì¶”ê°€

```python
def add_document(
    self,
    text: str,
    metadata: dict,
    organization_id: str,
    user_id: str,
    tags: Optional[List[str]] = None
) -> str:
    """
    ë¬¸ì„œë¥¼ OpenSearchì— ì €ì¥

    Process:
    1. í…ìŠ¤íŠ¸ â†’ ì„ë² ë”© ë²¡í„° ë³€í™˜ (OpenAI API í˜¸ì¶œ)
    2. ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ë¬¸ì„œ ìƒì„±
    3. OpenSearchì— ì¸ë±ì‹±

    Args:
        text: "OpenSearchëŠ” ê²€ìƒ‰ ì—”ì§„ì…ë‹ˆë‹¤"
        metadata: {"source": "ë¬¸ì„œA", "page": 10}
        organization_id: "org-123"
        user_id: "user-456"
        tags: ["ê¸°ìˆ ë¬¸ì„œ", "ê²€ìƒ‰"]

    Returns:
        ë¬¸ì„œ ID (UUID)
    """
    # 1. ì„ë² ë”© ìƒì„±
    embedding = self.llm_client.get_embedding(text)

    # 2. ë¬¸ì„œ êµ¬ì„±
    doc = {
        "text": text,
        "embedding": embedding,  # 3072ì°¨ì› ë²¡í„°
        "metadata": metadata,
        "organization_id": organization_id,
        "user_id": user_id,
        "tags": tags or [],
        "created_at": datetime.now().isoformat()
    }

    # 3. OpenSearchì— ì €ì¥
    doc_id = str(uuid.uuid4())
    self.client.index(
        index=self.index_name,
        id=doc_id,
        body=doc,
        refresh=True  # ì¦‰ì‹œ ê²€ìƒ‰ ê°€ëŠ¥í•˜ë„ë¡
    )

    return doc_id
```

### 6.3 í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ â­ í•µì‹¬!

```python
def search(
    self,
    query: str,
    organization_id: str,
    user_id: str,
    tags: Optional[List[str]] = None,
    limit: int = 5,
    use_hybrid: bool = True
) -> List[dict]:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: í‚¤ì›Œë“œ + ë²¡í„° ê²€ìƒ‰ ê²°í•©

    Example:
        query: "ë²¡í„° ê²€ìƒ‰ì´ë€?"

        â†’ ë‘ ê°€ì§€ ê²€ìƒ‰ ë™ì‹œ ì‹¤í–‰:
        1. í‚¤ì›Œë“œ ê²€ìƒ‰: "ë²¡í„°", "ê²€ìƒ‰" ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì„œ
        2. ë²¡í„° ê²€ìƒ‰: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ

        â†’ ê²°ê³¼ë¥¼ ì ìˆ˜ë¡œ í•©ì‚°í•˜ì—¬ ì •ë ¬
    """
    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = self.llm_client.get_embedding(query)

    # 2. í•„í„° ì¡°ê±´ (ì¡°ì§/ì‚¬ìš©ì/íƒœê·¸)
    filter_conditions = [
        {"term": {"organization_id": organization_id}},
        {"term": {"user_id": user_id}}
    ]
    if tags:
        filter_conditions.append({"terms": {"tags": tags}})

    # 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬
    search_body = {
        "size": limit,
        "query": {
            "bool": {
                "must": filter_conditions,  # í•„ìˆ˜ ì¡°ê±´
                "should": [  # ì ìˆ˜ í•©ì‚° (OR ì—°ì‚°)
                    # (1) í‚¤ì›Œë“œ ë§¤ì¹­
                    {
                        "match": {
                            "text": {
                                "query": query,
                                "boost": 1.0  # ê°€ì¤‘ì¹˜
                            }
                        }
                    },
                    # (2) ë²¡í„° ìœ ì‚¬ë„
                    {
                        "knn": {
                            "embedding": {
                                "vector": query_embedding,
                                "k": limit * 2  # í›„ë³´ ê°œìˆ˜
                            }
                        }
                    }
                ],
                "minimum_should_match": 1  # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­
            }
        }
    }

    # 4. ê²€ìƒ‰ ì‹¤í–‰
    response = self.client.search(
        index=self.index_name,
        body=search_body
    )

    # 5. ê²°ê³¼ ë³€í™˜
    results = []
    for hit in response["hits"]["hits"]:
        results.append({
            "text": hit["_source"]["text"],
            "score": hit["_score"],  # ê´€ë ¨ë„ ì ìˆ˜
            "metadata": hit["_source"].get("metadata", {})
        })

    return results
```

**í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ì¥ì **:

| ê²€ìƒ‰ ë°©ì‹ | ì¥ì  | ë‹¨ì  | ì˜ˆì‹œ |
|----------|------|------|------|
| **í‚¤ì›Œë“œ** | ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ | ë™ì˜ì–´ ëª»ì°¾ìŒ | "OpenSearch" â†’ "OpenSearch" âœ… |
| **ë²¡í„°** | ì˜ë¯¸ ì´í•´ | ì •í™•í•œ ë‹¨ì–´ ëª»ì°¾ìŒ | "ê²€ìƒ‰ ì—”ì§„" â†’ "OpenSearch" âœ… |
| **í•˜ì´ë¸Œë¦¬ë“œ** | ì–‘ìª½ ì¥ì  ê²°í•© | ì•½ê°„ ëŠë¦¼ | ìµœìƒì˜ ê²°ê³¼! |

**ì‹¤ìŠµ**:
```python
# OpenSearch ì—°ê²° í…ŒìŠ¤íŠ¸
from src.core.rag.opensearch_store import OpenSearchStore
from src.config.settings import settings

# 1. í´ë¼ì´ì–¸íŠ¸ ìƒì„±
store = OpenSearchStore(
    index_name="test_index",
    hosts=[{"host": settings.opensearch_host, "port": settings.opensearch_port}],
    http_auth=(settings.opensearch_user, settings.opensearch_password),
    use_ssl=settings.opensearch_use_ssl
)

# 2. ë¬¸ì„œ ì¶”ê°€
doc_id = store.add_document(
    text="FastAPIëŠ” Python ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë¹ ë¥´ê³  í˜„ëŒ€ì ì…ë‹ˆë‹¤.",
    metadata={"source": "ê³µì‹ ë¬¸ì„œ"},
    organization_id="org-test",
    user_id="user-test",
    tags=["Python", "FastAPI"]
)
print(f"ì¶”ê°€ëœ ë¬¸ì„œ ID: {doc_id}")

# 3. ê²€ìƒ‰
results = store.search(
    query="Python í”„ë ˆì„ì›Œí¬",
    organization_id="org-test",
    user_id="user-test",
    limit=3
)

for i, result in enumerate(results, 1):
    print(f"\n{i}. ì ìˆ˜: {result['score']:.2f}")
    print(f"   ë‚´ìš©: {result['text'][:50]}...")
```

---

## ğŸ§  Step 7: RAG ì—”ì§„ (3-4ì‹œê°„) â­ ê°€ì¥ ì¤‘ìš”!

### íŒŒì¼: `src/core/rag/rag_engine.py`

**í•™ìŠµ ëª©í‘œ**:
- RAG(Retrieval-Augmented Generation) ì „ì²´ í”Œë¡œìš° ì´í•´
- ê²€ìƒ‰ â†’ í”„ë¡¬í”„íŠ¸ êµ¬ì„± â†’ LLM í˜¸ì¶œ ê³¼ì • íŒŒì•…

### 7.1 RAGë€?

```
ì¼ë°˜ LLM:
User: "ìš°ë¦¬ íšŒì‚¬ í”„ë¡œì íŠ¸ A ì¼ì •ì€?"
GPT: "ì£„ì†¡í•©ë‹ˆë‹¤. ê·¸ ì •ë³´ëŠ” ëª¨ë¦…ë‹ˆë‹¤." âŒ

RAG:
User: "ìš°ë¦¬ íšŒì‚¬ í”„ë¡œì íŠ¸ A ì¼ì •ì€?"
  â†“
[1ë‹¨ê³„] ë²¡í„° DB ê²€ìƒ‰
  â†’ "í”„ë¡œì íŠ¸ Aì˜ ë§ˆê°ì¼ì€ 12ì›” 31ì¼..."
  â†“
[2ë‹¨ê³„] ê²€ìƒ‰ ê²°ê³¼ + ì§ˆë¬¸ â†’ GPT
  â†’ GPT: "í”„ë¡œì íŠ¸ Aì˜ ë§ˆê°ì¼ì€ 12ì›” 31ì¼ì…ë‹ˆë‹¤." âœ…
```

### 7.2 í•µì‹¬ ë©”ì„œë“œ

```python
# src/core/rag/rag_engine.py

class RAGEngine:
    """
    RAG(Retrieval-Augmented Generation) ì—”ì§„

    ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ LLM ë‹µë³€ ìƒì„±
    """

    def __init__(
        self,
        vector_store: OpenSearchStore,
        llm_model: str,
        temperature: float = 0.7,
        max_tokens: int = 2000
    ):
        self.vector_store = vector_store
        self.llm_client = OpenAIClient(...)
        self.temperature = temperature
        self.max_tokens = max_tokens

    def query(
        self,
        question: str,
        organization_id: str,
        user_id: str,
        tags: Optional[List[str]] = None,
        top_k: int = 3
    ) -> dict:
        """
        RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ

        Process:
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. ì§ˆë¬¸ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰           â”‚
        â”‚    "í”„ë¡œì íŠ¸ A ì¼ì •ì€?" â†’ ê²€ìƒ‰      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±       â”‚
        â”‚    [ë¬¸ì„œ 1] í”„ë¡œì íŠ¸ AëŠ”...         â”‚
        â”‚    [ë¬¸ì„œ 2] ë§ˆê°ì¼ì€ 12/31...       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸â”‚
        â”‚    â†’ GPT-4oì—ê²Œ ì „ë‹¬                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 4. GPT-4o ë‹µë³€ ìƒì„±                 â”‚
        â”‚    "í”„ë¡œì íŠ¸ Aì˜ ë§ˆê°ì¼ì€..."       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            organization_id: ì¡°ì§ ID (ë°ì´í„° ê²©ë¦¬)
            user_id: ì‚¬ìš©ì ID (ë°ì´í„° ê²©ë¦¬)
            tags: íƒœê·¸ í•„í„°
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜

        Returns:
            {
                "answer": "GPT ë‹µë³€",
                "sources": [ê²€ìƒ‰ëœ ë¬¸ì„œë“¤],
                "query": "ì›ë³¸ ì§ˆë¬¸"
            }
        """

        # ===== 1ë‹¨ê³„: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ =====
        logger.info(
            "RAG ê²€ìƒ‰ ì‹œì‘",
            question=question,
            organization_id=organization_id,
            user_id=user_id,
            top_k=top_k
        )

        search_results = self.vector_store.search(
            query=question,
            organization_id=organization_id,
            user_id=user_id,
            tags=tags,
            limit=top_k,
            use_hybrid=True  # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        )

        # ===== 2ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± =====
        context = self._build_context(search_results)

        # ===== 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ìƒì„± =====
        messages = [
            {
                "role": "system",
                "content": """ë‹¹ì‹ ì€ íšŒì‚¬ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
ë‹µë³€ ì‹œ ì¶œì²˜ ë²ˆí˜¸ [ë¬¸ì„œ N]ë¥¼ ë°˜ë“œì‹œ í‘œì‹œí•˜ì„¸ìš”."""
            },
            {
                "role": "user",
                "content": f"""ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

{context}

ì§ˆë¬¸: {question}"""
            }
        ]

        # ===== 4ë‹¨ê³„: LLM ë‹µë³€ ìƒì„± =====
        answer = self.llm_client.chat_completion(
            messages=messages,
            temperature=self.temperature,
            max_tokens=self.max_tokens
        )

        logger.info(
            "RAG ë‹µë³€ ìƒì„± ì™„ë£Œ",
            question=question,
            sources_count=len(search_results)
        )

        return {
            "answer": answer,
            "sources": search_results,
            "query": question
        }

    def _build_context(self, search_results: List[dict]) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        Args:
            search_results: [
                {"text": "í”„ë¡œì íŠ¸ AëŠ”...", "score": 0.95},
                {"text": "ë§ˆê°ì¼ì€...", "score": 0.87}
            ]

        Returns:
            "[ë¬¸ì„œ 1] í”„ë¡œì íŠ¸ AëŠ”...\n[ë¬¸ì„œ 2] ë§ˆê°ì¼ì€..."
        """
        if not search_results:
            return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        context_parts = []
        for i, result in enumerate(search_results, 1):
            context_parts.append(
                f"[ë¬¸ì„œ {i}] {result['text']}"
            )

        return "\n\n".join(context_parts)
```

**RAGì˜ í•µì‹¬ ì¥ì **:

1. **ìµœì‹  ì •ë³´**: í•™ìŠµ ë°ì´í„° ì™¸ì˜ ì •ë³´ í™œìš©
2. **í™˜ê°(Hallucination) ê°ì†Œ**: ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ìœ¼ë¡œ ì‹ ë¢°ì„± í–¥ìƒ
3. **ì¶œì²˜ ì¶”ì **: ì–´ë–¤ ë¬¸ì„œë¥¼ ì°¸ê³ í–ˆëŠ”ì§€ ëª…í™•íˆ í‘œì‹œ
4. **ë„ë©”ì¸ íŠ¹í™”**: íšŒì‚¬ ë‚´ë¶€ ë¬¸ì„œë¡œ ë§ì¶¤í˜• AI

**ì‹¤ìŠµ**:
```python
# RAG ì—”ì§„ í…ŒìŠ¤íŠ¸
from src.core.rag.rag_engine import RAGEngine
from src.core.rag.opensearch_store import OpenSearchStore
from src.config.settings import settings

# 1. Vector Store ì´ˆê¸°í™”
store = OpenSearchStore(
    index_name="ai_documents",
    hosts=[{"host": settings.opensearch_host, "port": settings.opensearch_port}],
    http_auth=(settings.opensearch_user, settings.opensearch_password),
    use_ssl=settings.opensearch_use_ssl
)

# 2. RAG ì—”ì§„ ì´ˆê¸°í™”
rag = RAGEngine(
    vector_store=store,
    llm_model="gpt-4o",
    temperature=0.7
)

# 3. ì§ˆì˜ì‘ë‹µ
result = rag.query(
    question="OpenSearchì˜ ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    organization_id="org-test-001",
    user_id="user-test-001",
    top_k=3
)

print("=" * 70)
print("ì§ˆë¬¸:", result["query"])
print("=" * 70)
print("\në‹µë³€:")
print(result["answer"])
print("\n" + "=" * 70)
print(f"ì°¸ê³  ë¬¸ì„œ ({len(result['sources'])}ê°œ):")
for i, source in enumerate(result["sources"], 1):
    print(f"\n{i}. ì ìˆ˜: {source['score']:.2f}")
    print(f"   ë‚´ìš©: {source['text'][:100]}...")
```

---

## ğŸŒ Step 8: REST API ë ˆì´ì–´ (2-3ì‹œê°„)

### íŒŒì¼: `src/api/rest/chat.py`

**í•™ìŠµ ëª©í‘œ**:
- FastAPI ë¼ìš°í„° êµ¬ì¡° ì´í•´
- ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´ í•™ìŠµ
- ì—ëŸ¬ í•¸ë“¤ë§ ë°©ë²•

### 8.1 ì±„íŒ… API ì—”ë“œí¬ì¸íŠ¸

```python
# src/api/rest/chat.py

from fastapi import APIRouter, HTTPException, Depends
from src.models.chat import ChatRequest, ChatResponse
from src.core.rag.rag_engine import RAGEngine

router = APIRouter(prefix="/api/v1", tags=["Chat"])

# ì˜ì¡´ì„±: RAG ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
def get_rag_engine() -> RAGEngine:
    """
    RAG ì—”ì§„ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    FastAPI ì˜ì¡´ì„± ì£¼ì… íŒ¨í„´
    """
    # ì•± ì‹œì‘ ì‹œ ì´ˆê¸°í™”ëœ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
    return rag_engine

@router.post("/chat", response_model=ChatResponse)
async def chat(
    request: ChatRequest,
    rag: RAGEngine = Depends(get_rag_engine)  # ì˜ì¡´ì„± ì£¼ì…
):
    """
    RAG ê¸°ë°˜ ì±„íŒ… API

    Request:
        POST /api/v1/chat
        {
            "message": "í”„ë¡œì íŠ¸ A ì¼ì •ì€?",
            "organization_id": "org-123",
            "user_id": "user-456",
            "session_id": "sess_abc"  # ì„ íƒ
        }

    Response:
        {
            "session_id": "sess_abc",
            "message": "í”„ë¡œì íŠ¸ Aì˜ ë§ˆê°ì¼ì€...",
            "sources": [
                {"text": "...", "score": 0.95}
            ],
            "suggestions": ["ê´€ë ¨ ì§ˆë¬¸ 1", "ê´€ë ¨ ì§ˆë¬¸ 2"],
            "timestamp": "2025-12-01T15:00:00"
        }
    """
    try:
        # 1. ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” ì¬ì‚¬ìš©
        session_id = request.session_id or f"sess_{uuid.uuid4().hex[:12]}"

        # 2. RAG ì¿¼ë¦¬ ì‹¤í–‰
        result = rag.query(
            question=request.message,
            organization_id=request.organization_id,
            user_id=request.user_id,
            top_k=3
        )

        # 3. ì‘ë‹µ êµ¬ì„±
        response = ChatResponse(
            session_id=session_id,
            message=result["answer"],
            sources=result["sources"],
            suggestions=_generate_suggestions(result),
            timestamp=datetime.now().isoformat()
        )

        # 4. ëŒ€í™” ì´ë ¥ ì €ì¥ (Redis)
        await _save_chat_history(session_id, request.message, result["answer"])

        logger.info(
            "ì±„íŒ… ì‘ë‹µ ì™„ë£Œ",
            session_id=session_id,
            user_id=request.user_id,
            sources_count=len(result["sources"])
        )

        return response

    except Exception as e:
        logger.error(
            "ì±„íŒ… ì²˜ë¦¬ ì‹¤íŒ¨",
            error=str(e),
            user_id=request.user_id
        )
        raise HTTPException(
            status_code=500,
            detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

def _generate_suggestions(result: dict) -> List[str]:
    """
    ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œ ì§ˆë¬¸ ìƒì„±
    """
    # ê°„ë‹¨í•œ í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±
    # ì‹¤ì œë¡œëŠ” LLMìœ¼ë¡œ ìƒì„± ê°€ëŠ¥
    return [
        "ê´€ë ¨ ë¬¸ì„œ ë” ì°¾ê¸°",
        "ë‹¤ë¥¸ í”„ë¡œì íŠ¸ ì •ë³´ ê²€ìƒ‰",
        "ì¼ì • í™•ì¸í•˜ê¸°"
    ]

async def _save_chat_history(session_id: str, question: str, answer: str):
    """
    Redisì— ëŒ€í™” ì´ë ¥ ì €ì¥

    Key: chat:history:{session_id}
    Value: [
        {"role": "user", "content": "ì§ˆë¬¸", "timestamp": "..."},
        {"role": "assistant", "content": "ë‹µë³€", "timestamp": "..."}
    ]
    """
    # Redis í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
    # êµ¬í˜„ ìƒëµ (src/utils/redis_client.py ì°¸ì¡°)
    pass
```

**FastAPI í•µì‹¬ ê°œë…**:

1. **ì˜ì¡´ì„± ì£¼ì… (Dependency Injection)**:
   ```python
   def get_rag_engine() -> RAGEngine:
       return rag_engine

   async def chat(rag: RAGEngine = Depends(get_rag_engine)):
       # ragë¥¼ ì§ì ‘ ìƒì„±í•˜ì§€ ì•Šê³  ì£¼ì…ë°›ìŒ
       # í…ŒìŠ¤íŠ¸ ì‹œ Mockìœ¼ë¡œ êµì²´ ê°€ëŠ¥
   ```

2. **ìë™ ê²€ì¦**:
   ```python
   @router.post("/chat", response_model=ChatResponse)
   async def chat(request: ChatRequest):
       # Pydanticì´ ìë™ìœ¼ë¡œ:
       # - í•„ìˆ˜ í•„ë“œ ì²´í¬
       # - íƒ€ì… ë³€í™˜
       # - ìµœì†Œ/ìµœëŒ€ ê¸¸ì´ ê²€ì¦
   ```

3. **ìë™ ë¬¸ì„œí™”**:
   - Swagger UI: `http://localhost:8000/docs`
   - ReDoc: `http://localhost:8000/redoc`

### 8.2 ë¬¸ì„œ ê´€ë¦¬ API

**íŒŒì¼: `src/api/rest/documents.py`**

```python
# src/api/rest/documents.py

@router.post("/documents", response_model=DocumentAddResponse)
async def add_document(
    request: DocumentAddRequest,
    rag: RAGEngine = Depends(get_rag_engine)
):
    """
    ë¬¸ì„œ ì¶”ê°€ API

    Request:
        POST /api/v1/documents
        {
            "text": "OpenSearchëŠ”...",
            "metadata": {"source": "ê³µì‹ ë¬¸ì„œ"},
            "organization_id": "org-123",
            "user_id": "user-456",
            "tags": ["OpenSearch", "ê²€ìƒ‰"]
        }
    """
    doc_id = rag.add_document(
        text=request.text,
        metadata=request.metadata,
        organization_id=request.organization_id,
        user_id=request.user_id,
        tags=request.tags
    )

    return DocumentAddResponse(
        doc_id=doc_id,
        message="ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."
    )

@router.post("/documents/search", response_model=DocumentSearchResponse)
async def search_documents(
    request: DocumentSearchRequest,
    rag: RAGEngine = Depends(get_rag_engine)
):
    """
    ë¬¸ì„œ ê²€ìƒ‰ API (RAG ì—†ì´ ìˆœìˆ˜ ê²€ìƒ‰)
    """
    results = rag.search_documents(
        query=request.query,
        organization_id=request.organization_id,
        user_id=request.user_id,
        tags=request.tags,
        limit=request.limit
    )

    return DocumentSearchResponse(
        results=results,
        count=len(results)
    )

@router.get("/documents/stats")
async def get_stats(
    organization_id: str,
    user_id: str,
    rag: RAGEngine = Depends(get_rag_engine)
):
    """
    ë¬¸ì„œ í†µê³„ API

    Returns:
        {
            "total_documents": 150,
            "by_tags": {"Python": 50, "FastAPI": 30},
            "recent_uploads": 10
        }
    """
    # OpenSearch aggregation ì‚¬ìš©
    # êµ¬í˜„ ìƒëµ
    pass
```

**ì‹¤ìŠµ**:
```bash
# 1. ì„œë²„ ì‹¤í–‰
.venv/bin/python -m src.main

# 2. Swagger UI ì ‘ì†
# ë¸Œë¼ìš°ì €: http://localhost:8000/docs

# 3. API í…ŒìŠ¤íŠ¸ (curl)
# ë¬¸ì„œ ì¶”ê°€
curl -X POST http://localhost:8000/api/v1/documents \
  -H "Content-Type: application/json" \
  -d '{
    "text": "FastAPIëŠ” ë¹ ë¥¸ Python ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤",
    "metadata": {"source": "í•™ìŠµìë£Œ"},
    "organization_id": "org-test",
    "user_id": "user-test",
    "tags": ["Python", "FastAPI"]
  }'

# ì±„íŒ…
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "FastAPIì— ëŒ€í•´ ì•Œë ¤ì¤˜",
    "organization_id": "org-test",
    "user_id": "user-test"
  }'
```

---

## ğŸš€ Step 9: ì „ì²´ í”Œë¡œìš° ì´í•´ (2ì‹œê°„)

### íŒŒì¼: `src/main.py`

**í•™ìŠµ ëª©í‘œ**:
- FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” ê³¼ì •
- ë¼ìš°í„° ë“±ë¡ ë° CORS ì„¤ì •
- ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬

```python
# src/main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager

from src.config.settings import settings
from src.api.rest import chat, documents, health
from src.core.rag.rag_engine import RAGEngine
from src.utils.logger import logger

# ì „ì—­ ë³€ìˆ˜ (ì‹±ê¸€í†¤)
rag_engine: RAGEngine = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬

    ì‹œì‘ ì‹œ:
    - OpenSearch ì—°ê²°
    - RAG ì—”ì§„ ì´ˆê¸°í™”
    - Redis ì—°ê²°

    ì¢…ë£Œ ì‹œ:
    - ì—°ê²° ì •ë¦¬
    """
    # ===== ì‹œì‘ ì´ë²¤íŠ¸ =====
    logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘", environment=settings.environment)

    # 1. OpenSearch ì—°ê²° í™•ì¸
    logger.info("OpenSearch ì—°ê²° ì¤‘", host=settings.opensearch_host)

    # 2. RAG ì—”ì§„ ì´ˆê¸°í™”
    global rag_engine
    rag_engine = RAGEngine(
        vector_store=None,  # ìë™ ìƒì„±
        llm_model=settings.openai_model,
        temperature=settings.openai_temperature,
        max_tokens=settings.openai_max_tokens,
        use_opensearch=True  # OpenSearch ì‚¬ìš©
    )
    logger.info("RAG ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")

    # 3. Redis ì—°ê²° (ëŒ€í™” ì´ë ¥ìš©)
    logger.info("Redis ì—°ê²° ì¤‘", url=settings.redis_url)

    yield  # ì—¬ê¸°ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰

    # ===== ì¢…ë£Œ ì´ë²¤íŠ¸ =====
    logger.info("ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ")
    # ì—°ê²° ì •ë¦¬ ë¡œì§

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="AI Assistant API",
    description="RAG ê¸°ë°˜ AI ì–´ì‹œìŠ¤í„´íŠ¸",
    version="0.1.0",
    lifespan=lifespan  # ìƒëª…ì£¼ê¸° í•¸ë“¤ëŸ¬ ë“±ë¡
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins.split(","),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(health.router)  # /health
app.include_router(chat.router)    # /api/v1/chat
app.include_router(documents.router)  # /api/v1/documents

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "service": "AI Assistant",
        "version": "0.1.0",
        "status": "running"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "src.main:app",
        host=settings.host,
        port=settings.port,
        reload=settings.debug  # ê°œë°œ ëª¨ë“œì—ì„œ ìë™ ë¦¬ë¡œë“œ
    )
```

**ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ í”Œë¡œìš°**:

```
1. main.py ì‹¤í–‰
   â†“
2. FastAPI ì•± ìƒì„±
   â†“
3. lifespan ì‹œì‘ ì´ë²¤íŠ¸
   - OpenSearch ì—°ê²°
   - RAG ì—”ì§„ ì´ˆê¸°í™”
   - Redis ì—°ê²°
   â†“
4. ë¼ìš°í„° ë“±ë¡
   - /health
   - /api/v1/chat
   - /api/v1/documents
   â†“
5. Uvicorn ì„œë²„ ì‹œì‘
   - http://localhost:8000
   â†“
6. ìš”ì²­ ëŒ€ê¸°...
   â†“
7. ì¢…ë£Œ ì‹ í˜¸ (Ctrl+C)
   â†“
8. lifespan ì¢…ë£Œ ì´ë²¤íŠ¸
   - ì—°ê²° ì •ë¦¬
   â†“
9. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ
```

---

## 5. ì‹¤ìŠµ ì˜ˆì œ

### ì‹¤ìŠµ 1: ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ êµ¬ì¶• (1ì‹œê°„)

**ëª©í‘œ**: ì²˜ìŒë¶€í„° ëê¹Œì§€ RAG ì‹œìŠ¤í…œ ì‹¤í–‰í•´ë³´ê¸°

```python
# practice_1_simple_rag.py

"""
ì‹¤ìŠµ 1: ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸

ëª©í‘œ:
1. ë¬¸ì„œ 3ê°œ ì¶”ê°€
2. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
3. RAG ì§ˆì˜ì‘ë‹µ
"""

from src.core.rag.opensearch_store import OpenSearchStore
from src.core.rag.rag_engine import RAGEngine
from src.config.settings import settings

# ===== Step 1: ë°ì´í„° ì¤€ë¹„ =====
documents = [
    {
        "text": "FastAPIëŠ” Pythonìœ¼ë¡œ ì‘ì„±ëœ í˜„ëŒ€ì ì¸ ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. íƒ€ì… íŒíŒ…ì„ ê¸°ë°˜ìœ¼ë¡œ ìë™ ê²€ì¦ê³¼ ë¬¸ì„œí™”ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
        "tags": ["Python", "FastAPI", "ì›¹ê°œë°œ"]
    },
    {
        "text": "OpenSearchëŠ” Elasticsearchì˜ ì˜¤í”ˆì†ŒìŠ¤ í¬í¬ì…ë‹ˆë‹¤. ê²€ìƒ‰ ì—”ì§„ê³¼ ë¶„ì„ ë„êµ¬ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
        "tags": ["OpenSearch", "ê²€ìƒ‰", "ë°ì´í„°ë² ì´ìŠ¤"]
    },
    {
        "text": "RAGëŠ” ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ AI ê¸°ìˆ ì…ë‹ˆë‹¤. ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•˜ì—¬ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
        "tags": ["AI", "RAG", "LLM"]
    }
]

# ===== Step 2: OpenSearch ì—°ê²° =====
print("=" * 70)
print("OpenSearch ì—°ê²° ì¤‘...")
print("=" * 70)

store = OpenSearchStore(
    index_name="practice_index",
    hosts=[{"host": settings.opensearch_host, "port": settings.opensearch_port}],
    http_auth=(settings.opensearch_user, settings.opensearch_password),
    use_ssl=settings.opensearch_use_ssl
)

# ===== Step 3: ë¬¸ì„œ ì¶”ê°€ =====
print("\në¬¸ì„œ ì¶”ê°€ ì¤‘...")
doc_ids = []
for i, doc in enumerate(documents, 1):
    doc_id = store.add_document(
        text=doc["text"],
        metadata={"source": f"ì‹¤ìŠµ ë¬¸ì„œ {i}"},
        organization_id="practice-org",
        user_id="practice-user",
        tags=doc["tags"]
    )
    doc_ids.append(doc_id)
    print(f"  {i}. ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ: {doc_id[:8]}...")

# ===== Step 4: ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ =====
print("\n" + "=" * 70)
print("ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
print("=" * 70)

queries = [
    "Python ì›¹ í”„ë ˆì„ì›Œí¬",
    "ê²€ìƒ‰ ì—”ì§„",
    "AI ê¸°ìˆ "
]

for query in queries:
    print(f"\nì§ˆë¬¸: {query}")
    results = store.search(
        query=query,
        organization_id="practice-org",
        user_id="practice-user",
        limit=2
    )

    for i, result in enumerate(results, 1):
        print(f"  {i}. ì ìˆ˜ {result['score']:.2f}: {result['text'][:50]}...")

# ===== Step 5: RAG ì§ˆì˜ì‘ë‹µ =====
print("\n" + "=" * 70)
print("RAG ì§ˆì˜ì‘ë‹µ")
print("=" * 70)

rag = RAGEngine(
    vector_store=store,
    llm_model="gpt-4o",
    temperature=0.7
)

question = "FastAPIì™€ OpenSearchì˜ ì°¨ì´ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
print(f"\nì§ˆë¬¸: {question}")

result = rag.query(
    question=question,
    organization_id="practice-org",
    user_id="practice-user",
    top_k=3
)

print("\në‹µë³€:")
print(result["answer"])

print("\nì°¸ê³  ë¬¸ì„œ:")
for i, source in enumerate(result["sources"], 1):
    print(f"  [{i}] {source['text'][:60]}...")

# ===== Step 6: ì •ë¦¬ =====
print("\n" + "=" * 70)
print("ì¸ë±ìŠ¤ ì‚­ì œ (ì •ë¦¬)")
print("=" * 70)

# ì‹¤ìŠµ í›„ ì¸ë±ìŠ¤ ì‚­ì œ (ì„ íƒ)
# store.client.indices.delete(index="practice_index")
# print("ì¸ë±ìŠ¤ 'practice_index' ì‚­ì œ ì™„ë£Œ")
```

**ì‹¤í–‰**:
```bash
.venv/bin/python practice_1_simple_rag.py
```

### ì‹¤ìŠµ 2: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ vs ë²¡í„° ê²€ìƒ‰ ë¹„êµ (1ì‹œê°„)

**ëª©í‘œ**: ê²€ìƒ‰ ë°©ì‹ì— ë”°ë¥¸ ê²°ê³¼ ì°¨ì´ ì´í•´

```python
# practice_2_search_comparison.py

"""
ì‹¤ìŠµ 2: ê²€ìƒ‰ ë°©ì‹ ë¹„êµ

í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ vs ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰
"""

from src.core.rag.opensearch_store import OpenSearchStore
from src.config.settings import settings

# OpenSearch ì—°ê²°
store = OpenSearchStore(
    index_name="ai_documents",  # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚¬ìš©
    hosts=[{"host": settings.opensearch_host, "port": settings.opensearch_port}],
    http_auth=(settings.opensearch_user, settings.opensearch_password),
    use_ssl=settings.opensearch_use_ssl
)

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
test_queries = [
    "ë²¡í„° ê²€ìƒ‰",  # ì •í™•í•œ í‚¤ì›Œë“œ
    "ì˜ë¯¸ ê¸°ë°˜ íƒìƒ‰",  # ìœ ì‚¬í•œ ì˜ë¯¸
    "k-NN algorithm",  # ì˜ë¬¸ í‚¤ì›Œë“œ
]

for query in test_queries:
    print("=" * 70)
    print(f"ì§ˆë¬¸: {query}")
    print("=" * 70)

    # 1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    print("\n[í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰]")
    hybrid_results = store.search(
        query=query,
        organization_id="org-test-001",
        user_id="user-test-001",
        limit=3,
        use_hybrid=True
    )

    for i, result in enumerate(hybrid_results, 1):
        print(f"{i}. ì ìˆ˜ {result['score']:.2f}")
        print(f"   {result['text'][:80]}...")

    print("\n")
```

### ì‹¤ìŠµ 3: íƒœê·¸ í•„í„°ë§ (30ë¶„)

```python
# practice_3_tag_filtering.py

"""
ì‹¤ìŠµ 3: íƒœê·¸ ê¸°ë°˜ í•„í„°ë§

ì¡°ì§/í”„ë¡œì íŠ¸ë³„ ë¬¸ì„œ ê²©ë¦¬
"""

from src.core.rag.opensearch_store import OpenSearchStore
from src.config.settings import settings

store = OpenSearchStore(
    index_name="ai_documents",
    hosts=[{"host": settings.opensearch_host, "port": settings.opensearch_port}],
    http_auth=(settings.opensearch_user, settings.opensearch_password),
    use_ssl=settings.opensearch_use_ssl
)

# ë‹¤ì–‘í•œ íƒœê·¸ë¡œ ë¬¸ì„œ ì¶”ê°€
documents = [
    ("í”„ë¡œì íŠ¸ AëŠ” ì›¹ ê°œë°œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.", ["í”„ë¡œì íŠ¸A", "ì›¹ê°œë°œ"]),
    ("í”„ë¡œì íŠ¸ BëŠ” ë°ì´í„° ë¶„ì„ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.", ["í”„ë¡œì íŠ¸B", "ë°ì´í„°"]),
    ("í”„ë¡œì íŠ¸ Aì˜ ë§ˆê°ì¼ì€ 12ì›”ì…ë‹ˆë‹¤.", ["í”„ë¡œì íŠ¸A", "ì¼ì •"]),
]

print("ë¬¸ì„œ ì¶”ê°€ ì¤‘...")
for text, tags in documents:
    store.add_document(
        text=text,
        metadata={},
        organization_id="org-practice",
        user_id="user-practice",
        tags=tags
    )
    print(f"  ì¶”ê°€: {tags}")

# íƒœê·¸ë³„ ê²€ìƒ‰
print("\n" + "=" * 70)
print("íƒœê·¸ í•„í„°ë§ ê²€ìƒ‰")
print("=" * 70)

# 1. "í”„ë¡œì íŠ¸A" íƒœê·¸ë§Œ
print("\n[í”„ë¡œì íŠ¸A ê´€ë ¨ ë¬¸ì„œë§Œ]")
results = store.search(
    query="í”„ë¡œì íŠ¸",
    organization_id="org-practice",
    user_id="user-practice",
    tags=["í”„ë¡œì íŠ¸A"],
    limit=5
)

for i, result in enumerate(results, 1):
    print(f"{i}. {result['text']}")

# 2. "ì¼ì •" íƒœê·¸ë§Œ
print("\n[ì¼ì • ê´€ë ¨ ë¬¸ì„œë§Œ]")
results = store.search(
    query="í”„ë¡œì íŠ¸",
    organization_id="org-practice",
    user_id="user-practice",
    tags=["ì¼ì •"],
    limit=5
)

for i, result in enumerate(results, 1):
    print(f"{i}. {result['text']}")
```

---

## 6. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 6.1 ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜

#### ì˜¤ë¥˜ 1: OpenSearch ì—°ê²° ì‹¤íŒ¨

```
ConnectionError: Connection to OpenSearch failed
```

**í•´ê²°ì±…**:
```bash
# 1. OpenSearch ì‹¤í–‰ í™•ì¸
curl -k -u admin:admin https://3.34.20.81:30920

# 2. .env ì„¤ì • í™•ì¸
cat .env | grep OPENSEARCH

# 3. ë°©í™”ë²½ í™•ì¸
# í¬íŠ¸ 30920ì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸
```

#### ì˜¤ë¥˜ 2: OpenAI API í‚¤ ì˜¤ë¥˜

```
AuthenticationError: Invalid API key
```

**í•´ê²°ì±…**:
```bash
# .env íŒŒì¼ í™•ì¸
echo $OPENAI_API_KEY

# API í‚¤ ìœ íš¨ì„± í…ŒìŠ¤íŠ¸
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

#### ì˜¤ë¥˜ 3: ì¸ë±ìŠ¤ ë§¤í•‘ ì˜¤ë¥˜

```
mapper_parsing_exception: nmslib engine is deprecated
```

**í•´ê²°ì±…**:
```python
# opensearch_store.pyì—ì„œ engine ë³€ê²½
"engine": "lucene",  # nmslib ëŒ€ì‹  lucene ì‚¬ìš©
```

#### ì˜¤ë¥˜ 4: ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜

```
dimension mismatch: expected 3072, got 1536
```

**í•´ê²°ì±…**:
```python
# ì˜¬ë°”ë¥¸ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
model="text-embedding-3-large"  # 3072ì°¨ì›
# model="text-embedding-3-small"  # 1536ì°¨ì› (ì‚¬ìš©X)
```

### 6.2 ë””ë²„ê¹… íŒ

```python
# 1. ë¡œê·¸ ë ˆë²¨ ë³€ê²½
# .env
LOG_LEVEL=DEBUG  # INFO â†’ DEBUGë¡œ ë³€ê²½

# 2. ìƒì„¸ ë¡œê·¸ í™•ì¸
logger.debug("ë³€ìˆ˜ ê°’", my_var=my_var)

# 3. OpenSearch ì¿¼ë¦¬ í™•ì¸
print(json.dumps(search_body, indent=2))

# 4. ì„ë² ë”© ë²¡í„° í™•ì¸
embedding = llm.get_embedding("í…ŒìŠ¤íŠ¸")
print(f"ì°¨ì›: {len(embedding)}, ì²˜ìŒ 5ê°œ: {embedding[:5]}")
```

---

## 7. ë‹¤ìŒ í•™ìŠµ ë‹¨ê³„

### 7.1 ì‹¬í™” í•™ìŠµ ì£¼ì œ

1. **ì„±ëŠ¥ ìµœì í™”**
   - OpenSearch HNSW íŒŒë¼ë¯¸í„° íŠœë‹
   - ì„ë² ë”© ìºì‹± ì „ëµ
   - ë°°ì¹˜ ì²˜ë¦¬

2. **ê³ ê¸‰ RAG ê¸°ë²•**
   - Re-ranking
   - Query expansion
   - Hybrid fusion ì•Œê³ ë¦¬ì¦˜

3. **í”„ë¡œë•ì…˜ ë°°í¬**
   - Docker ì»¨í…Œì´ë„ˆí™”
   - Kubernetes ë°°í¬
   - ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

4. **ë³´ì•ˆ ê°•í™”**
   - API ì¸ì¦/ì¸ê°€
   - Rate limiting
   - ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹

### 7.2 ì¶”ì²œ ë¦¬ì†ŒìŠ¤

#### ê³µì‹ ë¬¸ì„œ
- [FastAPI ê³µì‹ ë¬¸ì„œ](https://fastapi.tiangolo.com/)
- [OpenSearch ê³µì‹ ê°€ì´ë“œ](https://opensearch.org/docs/latest/)
- [OpenAI API ë ˆí¼ëŸ°ìŠ¤](https://platform.openai.com/docs/api-reference)

#### íŠœí† ë¦¬ì–¼
- [LangChain RAG íŠœí† ë¦¬ì–¼](https://python.langchain.com/docs/use_cases/question_answering/)
- [Pinecone RAG ê°€ì´ë“œ](https://www.pinecone.io/learn/retrieval-augmented-generation/)

#### ë…¼ë¬¸
- [RAG ì›ë…¼ë¬¸](https://arxiv.org/abs/2005.11401)
- [HNSW ì•Œê³ ë¦¬ì¦˜](https://arxiv.org/abs/1603.09320)

---

## 8. í•™ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ì´ˆ (í•„ìˆ˜)
- [ ] FastAPI ë¼ìš°í„°ì™€ ì—”ë“œí¬ì¸íŠ¸ ì´í•´
- [ ] Pydantic ëª¨ë¸ ì‚¬ìš©ë²•
- [ ] í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (settings.py)
- [ ] êµ¬ì¡°í™”ëœ ë¡œê¹…

### í•µì‹¬ (ì¤‘ìš”)
- [ ] OpenAI ì„ë² ë”© API ì‚¬ìš©ë²•
- [ ] OpenSearch k-NN ë²¡í„° ê²€ìƒ‰ ì›ë¦¬
- [ ] HNSW ì•Œê³ ë¦¬ì¦˜ ê°œë…
- [ ] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„
- [ ] RAG íŒŒì´í”„ë¼ì¸ ì „ì²´ í”Œë¡œìš°

### ì‹¬í™” (ì„ íƒ)
- [ ] Redis ëŒ€í™” ì´ë ¥ ê´€ë¦¬
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ë° ì¬ì‹œë„ ë¡œì§
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- [ ] í”„ë¡œë•ì…˜ ë°°í¬

---

## 9. ë§ˆë¬´ë¦¬

### í•™ìŠµ ëª©í‘œ ë‹¬ì„±ë„ ìê°€ í‰ê°€

| í•­ëª© | ë‹¬ì„±ë„ | ë¹„ê³  |
|------|--------|------|
| í”„ë¡œì íŠ¸ êµ¬ì¡° ì´í•´ | â˜ â˜ â˜ â˜ â˜ | |
| OpenSearch ë²¡í„° ê²€ìƒ‰ | â˜ â˜ â˜ â˜ â˜ | |
| RAG ì—”ì§„ êµ¬í˜„ | â˜ â˜ â˜ â˜ â˜ | |
| FastAPI í™œìš© | â˜ â˜ â˜ â˜ â˜ | |
| ì „ì²´ í”Œë¡œìš° ì´í•´ | â˜ â˜ â˜ â˜ â˜ | |

### ë‹¤ìŒ ì•¡ì…˜ ì•„ì´í…œ

1. [ ] ì‹¤ìŠµ ì˜ˆì œ 3ê°œ ëª¨ë‘ ì‹¤í–‰í•´ë³´ê¸°
2. [ ] ìì‹ ë§Œì˜ ë¬¸ì„œë¡œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•
3. [ ] í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ ì‹œë„
4. [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™”
5. [ ] í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„

---

**í•™ìŠµì— ë„ì›€ì´ ë˜ì…¨ê¸°ë¥¼ ë°”ëë‹ˆë‹¤! ê¶ê¸ˆí•œ ì ì€ ì–¸ì œë“  ë¬¸ì˜í•´ì£¼ì„¸ìš”.**

---

## ë¶€ë¡: ìš©ì–´ ì‚¬ì „

| ìš©ì–´ | ì„¤ëª… |
|------|------|
| **RAG** | Retrieval-Augmented Generation, ê²€ìƒ‰ ì¦ê°• ìƒì„± |
| **ì„ë² ë”© (Embedding)** | í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•œ ê²ƒ |
| **k-NN** | k-Nearest Neighbors, k-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ |
| **HNSW** | Hierarchical Navigable Small World, ê³„ì¸µì  ê·¸ë˜í”„ ê¸°ë°˜ ê²€ìƒ‰ |
| **ì½”ì‚¬ì¸ ìœ ì‚¬ë„** | ë‘ ë²¡í„° ê°„ ê°ë„ë¡œ ìœ ì‚¬ë„ ì¸¡ì • (-1 ~ 1) |
| **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** | í‚¤ì›Œë“œ + ë²¡í„° ê²€ìƒ‰ ê²°í•© |
| **Pydantic** | Python ë°ì´í„° ê²€ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| **ì˜ì¡´ì„± ì£¼ì…** | ê°ì²´ë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì…ë°›ëŠ” ë””ìì¸ íŒ¨í„´ |
| **Uvicorn** | FastAPI ì‹¤í–‰ìš© ASGI ì„œë²„ |
